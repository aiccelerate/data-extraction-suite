kafka.bootstrap-servers = ["asel-kafka:9093", "asel-kafka:9094"]

feast-engine {
  # Default tine zone for processing data (e.g. local dates in FHIR content, etc)
  # Shuld be string representation of java.time.ZoneId (using ZoneId.of for parsing), If not given default time zone of the deployed machine is used
  #default-time-zone = ""
  # Number of internal akka projection processors (akka projection)
  num-of-processors = 2
  # Number of fhir resources to query per page
  num-records-per-page = 500
  # Number of parallel FHIR query per extraction job
  num-parallel-query-per-job = 2
  # Number of entities in a group for distributed population processing
  num-entities-per-group = 20
  # Number of Kafka partitions for internal events
  num-of-kafka-partitions-for-external-events = 8
  # Number of entities per group for feature extraction
  num-entities-per-group-for-extraction = 10000
  # Configurations about the data source (FHIR API opening the source FHIR data)
  fhir-source {
    server-url = "http://localhost:8081/fhir"
    # If authorization is enabled (supporting Smart On Fhir authorization logic based on OpenID connect) provide the followings
    #authz {
      # Client identifier assigned to onfhir-feast engine for authorization
      #client-id = "<OPENID-CONNECT-CLIENT-IDENTIFIER>"
      # Client secret given to onfhir-feast engine for authorization
      #client-secret  = "<OPENID-CONNECT-CLIENT-SECRET>"
      # Token endpoint for the authorization server
      #token-endpoint = "<TOKEN-ENDPOINT>"
      # Token endpoint client authentication method; e.g. 'client_secret_basic', 'client_secret_post' or 'client_secret_jwt'
      #token-endpoint-auth-method = "<AUTHZ-METHOD-NAME>"
      #List of scopes required for authorization to FHIR data access
      #required-scopes=[]
    #}
  }

  # Folder path for provision of feature-group, population, etc definitions to the feast-engine (If not given feast-engine will only get definitions through its REST API)
  # The folder should have a special subdirectory structure;
  # 'feature-groups' sub folder should include feature group definitions
  # 'populations' sub folder should include population definitions
  # 'feature-sets' sub folder should include feature set definitions
  # 'pipelines' sub folder should include dataset extraction pipeline definitions
  definitions-folder = "./definitions/pilot2"

  # Configuration about the repository for time series data and population (list of entities for defined populations)
  time-series-repository  {
    # Type of the repository (Currently we are supporting 'timescaledb' which indicates Timescaledb database)
    type = "timescaledb"
    # Settings for the repository
    settings = ${feast-engine.slick-tsdb}
  }
  # Configuration for the repository for features
  offline-repository {
    # Type of the repository (Currently we are supporting 'timescaledb' which indicates Timescaledb database)
    #type = "timescaledb"
    type = "file-system"
    # Settings for the repository
    #settings = ${feast-engine.slick-tsdb}
    settings = {
      root-folder = "./datasets"
      format = "parquet"
    }
  }
  # Settings for data catalog repository (metadata about datasets)
  data-catalog {
    # Store the metadata into file system as excel format
    type = "file-system",
    settings {
      root-folder = "./data-catalog"
      format = "xls"
    }
  }

  # Example configuration for Postgres/Timescale as time series and/or population repository
  slick-tsdb {
    profile = "slick.jdbc.PostgresProfile$"
    # Database settings
    db {
      dataSourceClass = "slick.jdbc.DriverDataSource"
      properties = {
        driver = "org.postgresql.Driver"
        url = "jdbc:postgresql://"${akka-persistence-jdbc.shared-databases.slick.db.host}":"${akka-persistence-jdbc.shared-databases.slick.db.port}"/"${akka-persistence-jdbc.shared-databases.slick.db.dbname}
        user = ${akka-persistence-jdbc.shared-databases.slick.db.user}
        password = ${akka-persistence-jdbc.shared-databases.slick.db.password}
      }
    }
    # Whether Timescaledb is deployed as multi node or single node
    is-distributed = false
    # Number of partitions in Timescale
    num-of-partitions = 4
  }
}

akka {
  actor {
    provider = "cluster"
    #Serialization for distributed data
    serializers {
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
    }
    serialization-bindings {
      "io.onfhir.feast.model.JacksonSerializable" = jackson-json
    }
  }
  remote.artery {
    canonical {
      hostname = "127.0.0.1"
      port = 2551
    }
  }

  cluster {
    seed-nodes = ["akka://onfhir-feast-engine@127.0.0.1:2551"]
    roles = ["initializer"]
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  # Akka persistence settings
  persistence {
    journal.plugin = "jdbc-journal"
    auto-start-journals = ["jdbc-journal"]

    snapshot-store.plugin = "jdbc-snapshot-store"
    auto-start-snapshot-stores = ["jdbc-snapshot-store"]
  }

  #Akka projection settings
  projection {
    slick {
      # Using postgres for storing offsets
      dialect = postgres-dialect
      db = ${akka-persistence-jdbc.shared-databases.slick}
      blocking-jdbc-dispatcher.thread-pool-executor.fixed-pool-size = 3
    }
  }
}

# Postgres details for akka persistence
akka-persistence-jdbc {
  shared-databases {
    slick {
      profile = "slick.jdbc.PostgresProfile$"
      db {
        host = "localhost"
        port = 5432
        dbname = "onfhir_feast"
        url = "jdbc:postgresql://"${akka-persistence-jdbc.shared-databases.slick.db.host}":"${akka-persistence-jdbc.shared-databases.slick.db.port}"/"${akka-persistence-jdbc.shared-databases.slick.db.dbname}"?reWriteBatchedInserts=true"
        user = "postgres"
        password = "password"
        driver = "org.postgresql.Driver"
        numThreads = 20
        maxConnections = 20
        minConnections = 1
      }
    }
  }
}

jdbc-journal {
  use-shared-db = "slick"
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  use-shared-db = "slick"
}

# the akka-persistence-query provider in use
jdbc-read-journal {
  use-shared-db = "slick"
}
